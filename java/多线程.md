## 并发
* 多个任务交替执行
* 多个任务之间有可能还是串行

## 并行
* 同时执行

## 并发级别
### 阻塞
* synchronized
* 重入锁
### 无饥饿
* 非公平锁 高优先级的线程插队，低优先级线程产生饥饿
### 无障碍
* 非阻塞调度
### 无锁
### 无等待

## java内存模型（JMM）
* 原子性
  * 一个操作是不可中断的
    * long类型不是原子性的
* 可见性
  * 一个线程修改公共区域的值时，其他线程是否能够立即知道这个修改
* 有序性
  * 程序在执行时，可能会进行指令重排，重排后的指令与原指令的顺序未必一致
    * 指令重排可以保证串行语义一致，但是没有义务保证多线程的语义也一致
  * 指令不能重排：Happen-Before规则
    * 程序顺序原则
    * volatile
    * 锁规则
    * 传递性
    * 线程start()优先它的每一个动作
    * 线程的所有操作优先于线程的终结
    * 线程的中断（interrupt()）先于被中断线程的代码
    * 对象的构造函数的执行、结束先于finalize()方法
 
## 进程
* 系统进行资源分配和调度的基本单位，是操作系统结构的基础
* 线程就是轻量级进程，是程序执行的最小单位

## 线程状态
* NEW
* RUNNABLE
* BLOCKED
* WAITING
* TIMED_WAITING
* TERMINATED

## volatile
* 保证变量的可见性
* 有序性
* 只能确保一个线程修改了数据后，其他线程能够看到这个修改。但当两个线程同时修改某一个数据时，依然会产生冲突
* 无法保证一些复合操作的原子性，比如： i++
* 实现原理
  * [volatile的使用及其原理](https://www.cnblogs.com/paddix/p/5428507.html)
* 缓存一致性协议MESI MESI协议保证了每个缓存变量中使用的共享变量的副本都是一致的
  * 如果在短时间内产生大量的cas操作在加上 volatile的嗅探机制则会不断地占用总线带宽，导致总线流量激增
  * [Volatile 和 CAS 的弊端之总线风暴](https://cloud.tencent.com/developer/article/1707875)

## synchronized
* 指定加锁对象：对给定对象加锁，进入同步代码前要获得给定对象锁
* 直接作用于实例方法：相当于对当前实例加锁，进入同步代码前要获得当前对象锁
* 直接作用于静态方法：相当于对当前类加锁，进入同步代码前要获得当前类的锁
* 实现原理
   * [synchronized 实现原理](https://xiaomi-info.github.io/2020/03/24/synchronized/)

## AbstractQueuedSynchronizer(AQS)
> 抽象的队列式的同步器，AQS定义了一套多线程访问共享资源的同步器框架，许多同步类实现都依赖于它，如常用的ReentrantLock/Semaphore/CountDownLatch。AQS是一种提供了原子式管理同步状态、阻塞和唤醒线程功能以及队列模型的简单框架
### 原理
> AQS核心思想是，如果被请求的共享资源空闲，那么就将当前请求资源的线程设置为有效的工作线程，将共享资源设置为锁定状态；如果共享资源被占用，就需要一定的阻塞等待唤醒机制来保证锁分配。这个机制主要用的是CLH队列的变体实现的，将暂时获取不到锁的线程加入到队列中。CLH：Craig、Landin and Hagersten队列，是单向链表，AQS中的队列是CLH变体的虚拟双向队列（FIFO），AQS是通过将每条请求共享资源的线程封装成一个节点来实现锁的分配
* AQS使用一个Volatile的int类型的成员变量来表示同步状态，通过内置的FIFO队列来完成资源获取的排队工作，通过CAS完成对State值的修改
* AQS中最基本的数据结构——Node，Node即为CLH变体队列中的节点
* 线程两种锁的模式
  *  SHARED 	表示线程以共享的模式等待锁
  *  EXCLUSIVE 表示线程正在以独占的方式等待锁

## 重入锁 ReentrantLock
* jdk5以前 性能优于关键字synchronized 以后版本差别不大
* 手动指定何时加锁，何时释放锁
* 可反复重入的
* 中断响应
  * lock.lockInterruptibly
  * 锁申请等待限时  tryLock(long timeout, TimeUnit unit)
  * lock.isHeldByCurrentThread() 查询当前线程是否持有此锁
## 公平锁 FairLock
* 非公平锁 大多数情况下，锁的申请都是非公平的，从这个锁的等待队列随机挑选
* 公平锁 按照时间的先后顺序，保证先到先得，后到后得
* 公平锁 不会产生饥饿现象
* 维护一个有序队列，性能比较低
## Condition
* await/signal
* lock对象与Condition对象绑定
## 信号量 Semaphore
* 指定多个线程访问某一资源
* 指定信号量准入数，则同时能申请多少个许可
## 读写锁 ReadWriteLock 
* 有效地减少锁竞争，提升系统性能
## CountDownLatch
* 主线程在CountDownLatch上等待，当所有检查任务全部完成后，主线程才能继续执行
## CyclicBarrier 循环栅栏
* 多线程并发控制工具
* CyclicBarrier(int parties, Runnable barrierAction)
* barrierAction就是当计数器一次计数完成后，系统会执行的动作
## LockSupport 线程阻塞工具类 
* 线程内任意位置让线程阻塞
* park()/unpark()
* 类似于信号量的机制，它为每一个线程准备了一个许可，如果许可可用，那么park()方法会立即返回，并且取消这个许可（许可->不可用）
* 如果许可不可用，就会阻塞，而unpark()方法则使得一个许可变为可用
* 与信号量不同的是，许可不能累加，不可能拥有超过一个许可，它永远只有一个
## Guava和RateLimiter限流
### 漏桶算法
> 利用一个缓存区，当有请求进入系统时，无论请求的速率如何，都先在缓存区内保存，然后以固定的流速流出缓存区进行处理
* 无论外部请求压力如何，漏桶算法总是以固定的流速处理数据
* 漏桶的容积
* 流出速率
### 令牌桶算法
> 一种反向的漏桶算法。在令算法中，桶中存放的不再是请求，而是令牌。处理程序只有拿到令牌后，才能对请求进行处理。如果没有令牌，那么处理程序要么丢弃请求，要么等待可用的令牌。为了限制流速，
该算法在每个单位时间产生一定量的令牌存入桶中
* RateLimiter

## 线程复用-线程池
* ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit,BlockingQueue<Runnable> workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler) 
* 当线程数量过大时，反而会耗尽cpu和内存资源
* 大量的线程回收也会给GC带来很大的压力，延长GC的停顿时间
* Executor框架 ThreadPoolExecutor
  * newFixedThreadPool 固定线程数量的线程池
  * newSingleThreadExecutor 只用一个线程的线程池
  * newCachedThreadPool 可根据实际情况调整线程数量的线程
  * newSingleThreadScheduledExecutor 在给定时间执行某任务的功能 线程池大小为1
  * newScheduledThreadPool   在给定时间执行某任务的功能
*  ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit,BlockingQueue<Runnable> workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler)  
   * corePoolSize 线程池线程数量
   * maximumPoolSize 线程池最大线程数量
   * keepAliveTime 当线程池线程数量超过corePoolSize时，多余的空闲线程的存活时间，即超过corePoolSize的空闲线程，在多长时间内会被销毁
   * unit keepAliveTime的时间单位
   * workQueue 任务队列，被提交但尚未被执行的任务
   * threadFactory 线程工厂，用于创建线程，一般默认即可
   * handler 拒绝策略
* 扩展线程池
   * beforeExecute
   * afterExecute
   * terminated
* 优化线程池线程数量
  * Nthreads = Ncpu * Ucpu * (1 + W/C)
    * Ncpu CPU的数量
    * 目标CPU的使用率 0<=Ucpu<=1
    * W/C 等待时间与计算时间的比率
* 线程池可能会吃掉异常，导致程序的错误异常一无所知
  * submit()方法换成execute()方法
## 分而治之-fork/join框架
* 大任务拆分成多个子任务（fork），再将子任务的结果汇总到一起（join）
* ForkJoinPool线程池
* 无锁的栈来管理空闲线程

## guava对线程池的扩展
* DirectExecutor线程池 总是将任务在当前线程中直接执行
  * MoreExecutors.directExecutor()
* Daemon线程池 不希望后台线程池阻止程序的退出，当系统执行完成后，即便有线程池存在，依然希望进程结束执行
* 对Future模式的扩展 

## jdk的并发容器
* ConcurrentHashMap
  * 分段锁
* CopyOnWriteArrayList
* ConcurrentLinkedQueue 高效并发队列，链表实现
* BlockingQueue 阻塞队列  通过链表、数组等实现
* ConcurrentSkipListMap  跳表实现
  * 快速查找的数据机构
  * 时间复杂度O(logn) 
  * 所有元素都是有序的
 
## JMH性能测试
* 毫秒级测试

## 提高锁性能
* 减少锁持有的时间
  * 锁持有时间过长，导致等待线程大量增加
  * 降低锁冲突的可能性
* 减小锁粒度
  * 削弱多线程锁竞争
* 用读写分离锁来替换独占锁
  * ReadWriteLock
  * 读多写少
* 锁分离 ？
* 锁粗化
  * 如果对同一个锁不停地进行请求、同步和释放，其本身也会消耗系统宝贵的资源，反而不利于性能的优化
  * 锁粗化-虚拟机在遇到一连串连续地对同一个锁不断进行请求和释放的操作时，便会把所有的锁操作整合成对锁的一次请求，从而减少对锁的请求同步的次数
## java虚拟机对锁的优化
* 锁偏向
  * 如果一个线程获得了锁，那么锁就进入偏向模式
  * -XX:+UseBiasedLocking 开启偏向锁
  * 不适用于锁竞争激烈场合（因为每次不同的线程来请求相同的锁）
* 轻量级锁
  * 偏向锁失败，虚拟机并不会立即挂起线程，会采用轻量级锁优化
  * 简单地将对象头部作为指针指向持有锁的线程堆栈的内部，判断一个线程是否持有对象锁。如果线程获得轻量级锁成功，则可以顺利进入临界区。如果轻量级锁加锁失败，则表示其他线程抢先争夺到了锁，那么当前线程的锁请求就会膨胀为重量级锁
* 自旋锁
  * 当前线程暂时无法获得锁，虚拟机会让当前线程做几个空循环（自旋），经过若干次循环后，如果可以得到锁，则顺利进入临界区，否则，才会真的将线程在操作系统层面挂起
* 锁消除
  * java虚拟机在JIT编译时，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁
  * 节省毫无意义的请求锁时间
  * 锁消除需要逃逸分析
  * 逃逸分析-观察某一个变量是否会跳出某一作用域
  * 逃逸分析必须在-server模式下进行，使用-XX:+DoEscapeAnalysis开启
  * -XX:++EliminateLocks开启锁消除
## ThreadLocal
* 及时回收对象 ThreadLocal.remove()
* 共享对象对于竞争的处理容易引起性能损失，应该考虑使用ThreadLocal为每个线程分配单独的对象
## 无锁
* 对并发控制而言，锁是一种悲观的策略
* 无锁是一种乐观的策略，所有的线程都可以在不停顿的状态下持续执行
* 无锁的策略使用比较交换（CAS，Compare And Swap）的技术来鉴别线程冲突，一旦检测到冲突产生，就重试当前操作直到没有冲突为止
* CAS算法
  * 包含三个参数CAS(V,E,N),其中V表示要更新的变量，E表示预期值，N表示新值
     * 当V值等于E值，才会将V的值设为N
     * 当V值不等于E值，说明其他线程做了更新，则当前线程什么都不做
     * 最后，CAS返回当前V的真实值
* AtomicInteger 
   * 自增 incrementAndGet()
* java的指针 Unsafe类
  * sun.misc.Unsafe 封装一些不安全的操作（指针）
  * 调用CAS原子指令
* AtomicReference 无锁的对象引用
  * 对普通的对象的引用，保证你在修改对象引用时的线程安全性
* AtomicStampedReference 带时间戳的对象引用
  * 对象指及时间戳都必须满足期望值，写入才会成功
* AtomicIntegerArray 数组也能无锁
  * int[]类型的封装
* AtomicIntegerFieldUpdater 
  * 让普通变量变成线程安全的需求
  * 不支持静态变量
* 无锁的Vector实现
  * LockFreeVector
  * amino并发包
* SynchronousQueue
  * transfer
  * 不仅存在竞争，而且会协助工作
## 死锁
  * 两个或者多个线程相互占用对方需要的资源，而都不进行释放，导致彼此之间相互等待对方释放资源，产生了无限制等待的现象

